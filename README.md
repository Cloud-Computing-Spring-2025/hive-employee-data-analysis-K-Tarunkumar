# HadoopHiveHue
Hadoop , Hive, Hue setup pseudo distributed  environment  using docker compose
Hereâ€™s an updated **README** with the additional Docker commands and detailed instructions included:

---

# Hive Employee Analysis

This project demonstrates how to perform employee data analysis using Hive, Hadoop, and Docker. The dataset includes employee details and department information, which are analyzed through various SQL queries.

## Prerequisites

- **Docker**: Make sure Docker is installed and running on your system.
- **Hadoop**: A Hadoop cluster should be running within Docker containers for HDFS storage.
- **Hive**: Hive should be set up in Docker to interact with HDFS and execute queries.

## Dataset

- **employees.csv**: Contains employee details such as ID, name, age, job role, salary, project, join date, and department.
- **departments.csv**: Contains department ID, name, and location.

## Setup Instructions

### 1. Docker Setup
Start the Hadoop Cluster
Run the following command to start the Hadoop cluster:
```sh 
docker compose up -d
```
#### A. Copy the CSV files to Docker container

To copy the datasets (`employees.csv` and `departments.csv`) into the Docker container:

```sh
docker cp /workspaces/hive-employee-data-analysis-K-Tarunkumar/input_dataset/employees.csv resourcemanager:/tmp/
docker cp /workspaces/hive-employee-data-analysis-K-Tarunkumar/input_dataset/departments.csv resourcemanager:/tmp/
```

#### B. Create HDFS directories

Ensure that the HDFS directories are created:

```sh
docker exec -it resourcemanager hadoop fs -mkdir -p /input
```

#### C. Upload the CSV files to HDFS

Now, move the datasets into HDFS:

```sh
docker exec -it resourcemanager hadoop fs -put /tmp/departments.csv /input/
docker exec -it resourcemanager hadoop fs -put /tmp/employees.csv /input/
```

#### D. Verify Files in HDFS

To confirm the files are uploaded:

```sh
docker exec -it resourcemanager hadoop fs -ls /input/
```

#### E. Access the Resourcemanager Container

For any internal inspection or modification within the container, run:

```sh
docker exec -it resourcemanager /bin/bash
```

You can also list the files in the `/tmp/` directory to ensure they are correctly copied:

```sh
docker exec -it resourcemanager ls -l /tmp/
```

### 2. Set up Hive and Create Tables

#### A. Open the Hive Shell

Start the Hive shell:

```sh
docker exec -it hive-server /bin/bash
hive
```

#### B. Create Database (if not exists)

Create a new database for the analysis:

```sql
CREATE DATABASE IF NOT EXISTS web_logs;
```

#### C. Use the Database

Switch to the created database:

```sql
USE web_logs;
```

#### D. Create Tables

Create the `employees` and `departments` tables:

```sql
CREATE TABLE IF NOT EXISTS employees_temp (
    emp_id INT,
    name STRING,
    age INT,
    job_role STRING,
    salary DOUBLE,
    project STRING,
    join_date DATE,
    department STRING
);

CREATE TABLE IF NOT EXISTS departments (
    department_id INT,
    department_name STRING,
    location STRING
);
```

#### E. Load Data into Hive Tables

Now, load the CSV files into the tables:

```sql
LOAD DATA INPATH '/input/employees.csv' INTO TABLE employees_temp;
LOAD DATA INPATH '/input/departments.csv' INTO TABLE departments;
```

### 3. Running Queries

Here are the queries for employee analysis:

#### A. Employees who joined after 2015

```sql
SELECT * FROM employees WHERE join_date > '2015-12-31';
```

#### B. Average salary per department

```sql
SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department;
```

#### C. Employees assigned to 'Alpha' project

```sql
SELECT * FROM employees WHERE project = 'Alpha';
```

#### D. Count of employees in each job role

```sql
SELECT job_role, COUNT(*) AS employee_count FROM employees GROUP BY job_role;
```

#### E. Employees earning above the department's average salary

```sql
SELECT e.* FROM employees e
JOIN (SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department) d
ON e.department = d.department
WHERE e.salary > d.avg_salary;
```

#### F. Department with the highest number of employees

```sql
SELECT department, COUNT(*) AS emp_count FROM employees GROUP BY department ORDER BY emp_count DESC LIMIT 1;
```

#### G. Exclude employees with null values

```sql
SELECT * FROM employees WHERE emp_id IS NOT NULL AND name IS NOT NULL AND age IS NOT NULL AND
job_role IS NOT NULL AND salary IS NOT NULL AND project IS NOT NULL AND join_date IS NOT NULL AND department IS NOT NULL;
```

#### H. Employee details with department location

```sql
SELECT e.*, d.location FROM employees e
JOIN departments d ON e.department = d.department_name;
```

#### I. Rank employees by salary within departments

```sql
SELECT emp_id, name, department, salary,
RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS salary_rank
FROM employees;
```

#### J. Top 3 highest-paid employees in each department

```sql
SELECT * FROM (
    SELECT emp_id, name, department, salary,
    RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS salary_rank
    FROM employees
) ranked_employees WHERE salary_rank <= 3;
```



